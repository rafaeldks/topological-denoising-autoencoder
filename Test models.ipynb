{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51991441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaeldks/anaconda3/envs/env_pytorch/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "import copy\n",
    "import torchvision\n",
    "import gudhi as gd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from keras.datasets import mnist\n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efce86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательная функция для отрисовки изображений\n",
    "def plot(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb61c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcc32994b58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "random.seed(12345)\n",
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a03ea",
   "metadata": {},
   "source": [
    "## Задание параметра шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5700fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 'topological'\n",
    "# noise = 'salt&pepper'\n",
    "# noise = 'gaussian'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830f80b",
   "metadata": {},
   "source": [
    "## Задаём модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b3688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_input, d_hidden):\n",
    "        super().__init__()\n",
    "        self.autoencoder = nn.Sequential(\n",
    "            MLP(d_input, d_hidden * 4, d_hidden),\n",
    "            MLP(d_hidden, d_hidden * 4, d_input)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.autoencoder(X)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, h_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, h_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(h_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d12b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training datapoints:60000\n",
      "No of Test datapoints:10000\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет\n",
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "print(\"No of training datapoints:{}\\nNo of Test datapoints:{}\".format(len(xtrain), len(xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13db068",
   "metadata": {},
   "source": [
    "## Нанесение шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e462275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаём вид шума\n",
    "def add_noise(img, noise_type):\n",
    "    if noise_type == 'topological':\n",
    "        row, col = 28, 28\n",
    "        coef = 0.2\n",
    "        img = img.astype(np.float32)\n",
    "        row, col = img.shape\n",
    "        num_of_lines = int((row + col) * coef)\n",
    "        for i in range(num_of_lines):\n",
    "            x1 = x2 = 0\n",
    "            while (x1 == x2):\n",
    "                x1, y1 = random.randint(0, col - 1), random.randint(0, row - 1)\n",
    "                x2, y2 = random.randint(0, col - 1), random.randint(0, row - 1)\n",
    "            k = (y2 - y1) / (x2 - x1)\n",
    "            b = y1 - k * x1\n",
    "            color = random.randint(0, 255)\n",
    "            for x in range(min(x1, x2) + 1, max(x1, x2) - 1):\n",
    "                y = round(k * x + b)\n",
    "                img[y][x] = color\n",
    "        return img\n",
    "    elif noise_type == 'gaussian':\n",
    "        coef = 0.2\n",
    "        row, col = img.shape\n",
    "        n = (np.random.normal(loc=0,\n",
    "                              scale=100 * coef,\n",
    "                              size=(row, col)))\n",
    "        return n.astype(int) + img\n",
    "    elif noise_type == 'salt&pepper':\n",
    "        coef = 0.2\n",
    "        image = copy.deepcopy(img)\n",
    "        row, col = image.shape\n",
    "\n",
    "        number_of_pixels = int(coef * row * col) // 2\n",
    "        for i in range(number_of_pixels):\n",
    "            y_coord = random.randint(0, row - 1)\n",
    "\n",
    "            x_coord = random.randint(0, col - 1)\n",
    "\n",
    "            image[y_coord][x_coord] = 255\n",
    "\n",
    "        for i in range(number_of_pixels):\n",
    "            y_coord = random.randint(0, row - 1)\n",
    "\n",
    "            x_coord = random.randint(0, col - 1)\n",
    "\n",
    "            image[y_coord][x_coord] = 0\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bd7da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 7038.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "topological noise addition completed to images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "noise_ct = 0\n",
    "noise_id = 0\n",
    "testdata = np.zeros((1000, 28, 28))\n",
    "\n",
    "for idx in tqdm(range(1000)):\n",
    "\n",
    "    if noise_ct < (len(xtest) / 2):\n",
    "        noise_ct += 1\n",
    "        x = add_noise(xtest[idx], noise_type=noise)\n",
    "        testdata[idx] = x\n",
    "\n",
    "    else:\n",
    "        print(\"\\n{} noise addition completed to images\".format(noise))\n",
    "        noise_id += 1\n",
    "        noise_ct = 0\n",
    "\n",
    "print(\"\\n{} noise addition completed to images\".format(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7618849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём класс для датасета\n",
    "\n",
    "class noisedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, datasetnoised, datasetclean, labels, transform):\n",
    "        self.noise = datasetnoised\n",
    "        self.clean = datasetclean\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noise)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xNoise = self.noise[idx]\n",
    "        xClean = self.clean[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        if self.transform != None:\n",
    "            xNoise = self.transform(xNoise)\n",
    "            xClean = self.transform(xClean)\n",
    "\n",
    "        return (xNoise, xClean, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5a5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём сеты для DataLoader'а\n",
    "tsfms = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "testset=noisedDataset(testdata,xtest,ytest,tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b7d5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Смотрим на пример зашумлённого изображения\n",
    "plot(testdata[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76d4f20",
   "metadata": {},
   "source": [
    "## Объявление функций потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1836258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения диаграммы устойчивости изображения\n",
    "def diagram(image):\n",
    "    # Получаем размер изображения\n",
    "    h = int(np.sqrt(image.shape[0]))\n",
    "    image_sq = image.reshape((h, h))\n",
    "\n",
    "    # Создаём кубический комплекс\n",
    "    cmplx = gd.CubicalComplex(dimensions=(h, h), top_dimensional_cells=image)\n",
    "\n",
    "    # Получаем персистентные пары для кубической фильтрации\n",
    "    cmplx.compute_persistence()\n",
    "    critical_pairs = cmplx.cofaces_of_persistence_pairs()\n",
    "\n",
    "    # Получаем номер пикселя в исходном изображении\n",
    "    bpx0_essential = critical_pairs[1][0][0] // h, critical_pairs[1][0][0] % h\n",
    "\n",
    "    # Получаем критические пиксели, соответствующие персистентным парам\n",
    "    try:\n",
    "        bpx0 = [[critical_pairs[0][0][i][0] // h, critical_pairs[0][0][i][0] % h] for i in\n",
    "                range(len(critical_pairs[0][0]))]\n",
    "        dpx0 = [[critical_pairs[0][0][i][1] // h, critical_pairs[0][0][i][1] % h] for i in\n",
    "                range(len(critical_pairs[0][0]))]\n",
    "    except IndexError:\n",
    "        bpx0 = [[]]\n",
    "        dpx0 = [[]]\n",
    "\n",
    "    try:\n",
    "        bpx1 = [[critical_pairs[0][1][i][0] // h, critical_pairs[0][1][i][0] % h] for i in\n",
    "                range(len(critical_pairs[0][1]))]\n",
    "        dpx1 = [[critical_pairs[0][1][i][1] // h, critical_pairs[0][1][i][1] % h] for i in\n",
    "                range(len(critical_pairs[0][1]))]\n",
    "    except IndexError:\n",
    "        bpx1 = [[]]\n",
    "        dpx1 = [[]]\n",
    "\n",
    "    idx0, idx1 = np.stack([bpx0, dpx0]).T, np.stack([bpx1, dpx1]).T\n",
    "\n",
    "    # Добавляем нулевой гомологический класс\n",
    "    pd0_essential = torch.tensor([[image_sq[bpx0_essential], torch.max(image)]])\n",
    "\n",
    "    # получаем диаграмму устойчивости через индексацию\n",
    "    if (len(idx0) != 0):\n",
    "        pd0 = image_sq[idx0]\n",
    "        pd0 = torch.vstack([pd0, pd0_essential])\n",
    "    else:\n",
    "        pd0 = pd0_essential\n",
    "\n",
    "    if (len(idx1) != 0):\n",
    "        pd1 = image_sq[idx1]\n",
    "    else:\n",
    "        pd1 = torch.zeros((1, 2))\n",
    "\n",
    "    return pd0, pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70aac103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для сравнения диаграмм устойчивости\n",
    "def compare(image1, image2):\n",
    "    first_pd0, first_pd1 = diagram(image1)\n",
    "    second_pd0, second_pd1 = diagram(image2)\n",
    "\n",
    "    return wasserstein_distance(first_pd0, second_pd0, enable_autodiff=True) + \\\n",
    "        wasserstein_distance(first_pd1, second_pd1, enable_autodiff=True)\n",
    "\n",
    "\n",
    "# Функция топологических потерь\n",
    "def topo_loss(output, target):\n",
    "    loss = torch.tensor(0.)\n",
    "    for i in range(len(output)):\n",
    "        loss += compare(output[i], target[i])\n",
    "    return (loss / len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd84325",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss_fn = nn.MSELoss()\n",
    "topo_loss_fn = topo_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf512dc",
   "metadata": {},
   "source": [
    "## Тестирование моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820fdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:13<00:00,  1.23it/s]\n",
      "100%|██████████| 16/16 [00:12<00:00,  1.29it/s]\n",
      "100%|██████████| 16/16 [00:12<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss Topo Loss\n",
      "5330.2656 602.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataloader_test = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "for i in range(1,4):\n",
    "    model = Autoencoder(28*28, 32)\n",
    "    # Здесь нужно указать путь к файлам с моделями\n",
    "    model.load_state_dict(torch.load(f\"/Users/rafaeldks/Desktop/MyProject/Topological/custom_model_{i}.pt\"))\n",
    "    mse_loss_epoch = []\n",
    "    topo_loss_epoch = []\n",
    "\n",
    "    for X, y, label in tqdm(dataloader_test):\n",
    "        X=X.view(X.size(0), -1).type(torch.FloatTensor).clone().detach().requires_grad_(True)\n",
    "        y=y.view(y.size(0), -1).type(torch.FloatTensor).clone().detach().requires_grad_(True)\n",
    "        mse_loss_batch = mse_loss_fn(model(X), y)\n",
    "        topo_loss_batch = topo_loss_fn(model(X), y)\n",
    "        \n",
    "        mse_loss_epoch.append(mse_loss_batch.detach())\n",
    "        topo_loss_epoch.append(topo_loss_batch.detach()) \n",
    "        \n",
    "mse_loss_mean = np.mean(mse_loss_epoch)\n",
    "topo_loss_mean = np.mean(topo_loss_epoch)\n",
    "print('MSE Loss', 'Topo Loss')\n",
    "print(mse_loss_mean, topo_loss_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
